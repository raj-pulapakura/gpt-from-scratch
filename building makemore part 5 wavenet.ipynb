{"cells":[{"cell_type":"markdown","metadata":{"id":"5BMqmrhk44ng"},"source":["# Previous code"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1705846936123,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"xh9X9UlnDfEX"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x1d77d491cd0>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(42)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1705838047743,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"lub5q8LcDuRs","outputId":"b0beec76-8f46-4241-b269-212628f63c04"},"outputs":[{"data":{"text/plain":["['emma',\n"," 'olivia',\n"," 'ava',\n"," 'isabella',\n"," 'sophia',\n"," 'charlotte',\n"," 'mia',\n"," 'amelia',\n"," 'harper',\n"," 'evelyn']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["words = open(\"names.txt\", \"r\").read().splitlines()\n","words[:10]"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705838048907,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"bPTQFew3Dy91"},"outputs":[],"source":["# build vocabulary\n","\n","chars = [\".\"] + sorted(list(set(\"\".join(words))))\n","stoi = { s:i for i,s in enumerate(chars) } # string to integer\n","itos = { i:s for s,i in stoi.items() } # integer to string"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["context_length = 3"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705838053677,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"hmvQdjPOckUc"},"outputs":[],"source":["def build_dataset(words):\n","  X, Y = [], []\n","\n","  for w in words:\n","    context = [0] * context_length\n","    for ch in w + \".\":\n","      ix = stoi[ch]\n","      X.append(context)\n","      Y.append(ix)\n","      context = context[1:] + [ix]\n","\n","  X = torch.tensor(X)\n","  Y = torch.tensor(Y)\n","  print(X.shape, Y.shape)\n","  return X, Y"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1125,"status":"ok","timestamp":1705838056441,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"GmmFY3RJcWtB","outputId":"13e4ee08-6da9-437e-8f55-d60372149b19"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([182625, 3]) torch.Size([182625])\n","torch.Size([22655, 3]) torch.Size([22655])\n","torch.Size([22866, 3]) torch.Size([22866])\n"]}],"source":["# build training, dev, test sets\n","\n","import random\n","\n","random.seed(42)\n","random.shuffle(words)\n","n1 = int(0.8*len(words))\n","n2 = int(0.9*len(words))\n","\n","Xtr, Ytr = build_dataset(words[:n1])\n","Xdev, Ydev = build_dataset(words[n1:n2])\n","Xte, Yte = build_dataset(words[n2:])"]},{"cell_type":"markdown","metadata":{"id":"jpVJgZWGZFaK"},"source":["# Initial code"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1705846961954,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"sj--1-H4ZE-f"},"outputs":[],"source":["class Linear:\n","\n","  def __init__(self, fan_in, fan_out, bias=True):\n","    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # kaiming init\n","    self.bias = torch.zeros(fan_out) if bias else None\n","\n","  def __call__(self, x):\n","    self.out = x @ self.weight\n","    if self.bias is not None:\n","      self.out += self.bias\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.weight] + ([] if self.bias is None else [self.bias])"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":300,"status":"ok","timestamp":1705847255960,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"Ua9Ky3_xZkIn"},"outputs":[],"source":["class BatchNorm1d:\n","\n","  def __init__(self, dim, eps=1e-5, momentum=0.1):\n","    self.eps = eps # to avoid divisionbyzero error when scaling\n","    self.momentum = momentum # to compute running average\n","    self.training = True\n","    # parameters (trained with backprop)\n","    self.gamma = torch.ones(dim)\n","    self.beta = torch.zeros(dim)\n","    # buffers (stored with a running momentum update)\n","    self.running_mean = torch.zeros(dim)\n","    self.running_var = torch.ones(dim)\n","\n","  def __call__(self, x):\n","    # calculate forward pass\n","    if self.training:\n","      xmean = x.mean(0, keepdim=True) # batch mean\n","      xvar = x.var(0, keepdim=True) # batch variance\n","    else:\n","      xmean = self.running_mean\n","      xvar = self.running_var\n","    xhat = (x-xmean) / torch.sqrt(xvar + self.eps)\n","    self.out = self.gamma * xhat + self.beta\n","    # update the bufers\n","    if self.training:\n","      with torch.no_grad():\n","        self.running_mean = (1-self.momentum) * self.running_mean + self.momentum * xmean\n","        self.running_var = (1-self.momentum) * self.running_var + self.momentum * xvar\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.gamma, self.beta]"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":360,"status":"ok","timestamp":1705847317085,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"vE_boYfra29a"},"outputs":[],"source":["class Tanh:\n","\n","  def __call__(self, x):\n","    self.out = torch.tanh(x)\n","    return self.out\n","\n","  def parameters(self):\n","    return []"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["class Embedding:\n","    def __init__(self, vocab_size, embed_dim):\n","        self.weight = torch.randn((vocab_size, embed_dim))\n","\n","    def __call__(self, IX):\n","        self.out = self.weight[IX]\n","        return self.out\n","    \n","    def parameters(self):\n","        return [self.weight]\n","    \n","class Flatten:\n","    def __call__(self, x):\n","        self.out = x.view(x.shape[0], -1)\n","        return self.out\n","    \n","    def parameters(self):\n","        return []"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["class Sequential:\n","    def __init__(self, layers):\n","        self.layers = layers\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        self.out = x\n","        return self.out\n","    \n","    def parameters(self):\n","        return [p for layer in self.layers for p in layer.parameters()]"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1705847915702,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"aT2CDriqbF7t","outputId":"f61ce06d-f5a5-43f0-e9c5-0e8a72432b5f"},"outputs":[{"name":"stdout","output_type":"stream","text":["46497\n"]}],"source":["n_embed = 10\n","n_hidden = 100\n","vocab_size = 27\n","\n","model = Sequential([\n","  Embedding(vocab_size, n_embed),\n","  Flatten(),\n","  Linear(n_embed * context_length, n_hidden), Tanh(),\n","  Linear(                n_hidden, n_hidden), Tanh(),\n","  Linear(                n_hidden, n_hidden), Tanh(),\n","  Linear(                n_hidden, n_hidden), Tanh(),\n","  Linear(                n_hidden, n_hidden), Tanh(),\n","  Linear(                n_hidden, vocab_size)\n","])\n","\n","with torch.no_grad():\n","  # last layer: make less confident\n","  model.layers[-1].weight *= 0.1\n","  # # all other layers: apply gain\n","  # for layer in model.layers[:-1]:\n","  #   if isinstance(layer, Linear):\n","  #     layer.weight *= 5/3 # only because we are using tanh\n","\n","parameters = model.parameters()\n","print(sum(p.nelement() for p in parameters))\n","for p in parameters:\n","  p.requires_grad = True"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316906,"status":"ok","timestamp":1705848233623,"user":{"displayName":"Raj Pulapakura","userId":"15990840560051697646"},"user_tz":-660},"id":"ENAaWtF7ci90","outputId":"14463c2a-9525-4971-924c-7a4ea6e9b4d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["      0/  30000: 3.3031\n","  10000/  30000: 2.1060\n","  20000/  30000: 2.0774\n"]}],"source":["max_steps = 30_000\n","batch_size = 128\n","\n","for i in range(1, max_steps+1):\n","  # construct minibatch\n","  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n","  Xb, Yb = Xtr[ix], Ytr[ix]\n","\n","  # forward pass\n","  logits = model(Xb)\n","  loss = F.cross_entropy(logits, Yb)\n","\n","  # backward pass\n","  for p in parameters:\n","    p.grad = None\n","  loss.backward()\n","\n","  # update\n","  lr = 0.1 if i < 100_000 else 0.01\n","  for p in parameters:\n","    p.data -= lr * p.grad\n","\n","  # track stats\n","  if i % 10_000 == 0:\n","    print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["for layer in model.layers:\n","    layer.training = False"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"vb5fOGLOcbvZ"},"outputs":[],"source":["@torch.no_grad()\n","def split_loss(split):\n","    x, y = {\n","        \"train\": (Xtr, Ytr),\n","        \"val\": (Xdev, Ydev),\n","        \"test\": (Xte, Yte)\n","    }[split]\n","    logits = model(x)\n","    loss = F.cross_entropy(logits, y)\n","    print(split, loss.item())"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train 2.0458154678344727\n","val 2.120760917663574\n"]}],"source":["split_loss(\"train\")\n","split_loss(\"val\")"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["zaxie.\n","alviena.\n","yenna.\n","mah.\n","sammitoco.\n","kiya.\n","blaterri.\n","kyma.\n","edvraxtyn.\n","ekatha.\n","zonaf.\n","davimmilan.\n","brayn.\n","elyston.\n","ten.\n","fylie.\n","cyossoyaan.\n","demba.\n","zei.\n","sorvectella.\n"]}],"source":["# sample from the model\n","\n","for _ in range(20):\n","    out = []\n","    context = [0] * context_length\n","    while True:\n","        logits = model(torch.tensor([context]))\n","        probs = F.softmax(logits, dim=1)\n","        # sample from distribution\n","        ix = torch.multinomial(probs, num_samples=1).item()\n","        # shift the context window and track the samples\n","        context = context[1:] + [ix]\n","        out.append(ix)\n","        # if we sample the \".\" token, break\n","        if ix == 0:\n","            break\n","\n","    print(\"\".join(itos[i] for i in out))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPyKpwxNCqQ5OuWVrL+c5HF","mount_file_id":"1L0XUJTbrqNYN1A7HOEuOaMw3TsGNFls_","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
